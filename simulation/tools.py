import pandas as pd
import numpy as np
from sklearn.model_selection import ShuffleSplit
from TFCox.utils import plot_km
from TFCox.simulation.simulator import SimulatedData

def survival_stats(data, T_col='T', E_col='E', plot=False):
    '''
    Print statistics of survival data.
    :param data: pandas.DataFrame
           Survival to require statistics.
    :param T_col: string
           Column name in data indicating time.
    :param E_col: string
           Column name in data indicating events.
    :param plot:boolean.
           Whether to plot survival curve.
    '''
    if not isinstance(data, pd.DataFrame):
        raise TypeError('Input survival data should be pandas.DataFrame')
    assert isinstance(data, pd.DataFrame)

    print('-'*10 + 'Survival Data Statistics' + '-'*10)
    N = data.shape[0]
    print('# Rows:', N)
    print('# Columns: %d + %s + %s' %(data.shape[1]-2, T_col, E_col))
    print('# Events Ratio: {0}'.format(np.sum(data[E_col]) / N))
    print('# Min Time:', np.min(data[T_col]))
    print('# Max Time:', np.max(data[E_col]))
    print('-' * 44)

    if plot:
        plot_km(data, T_col, E_col)


def surv_df(data, T_col='T', E_col='E', label_col='Y', exclude_col=[]):
    '''
    Transform raw data to the dataframe that can be used for survival analysis.
    :param data:pandas.DataFrame
           Survival data to be transformed.
    :param T_col:string
           Column name in raw data representing time.
    :param E_col:string
           Column name in raw data representing events or status.
    :param label_col:string
           Name of new label(representing time) in transformed survival data.
    :param exclude_col:list
           Columns to be excluded.
    :return:pandas.DataFrame
           Transformed survival data. Negative values in label are considered right censored.
    '''
    x_cols = [col for col in data.columns if col not in ([T_col, E_col] + exclude_col)]

    #Negative values are considered right censored.
    data.loc[:, label_col] = data.loc[:, T_col]
    data.loc[data[E_col] == 0, label_col] = - data.loc[data[E_col] == 0, label_col]
    return data[x_cols + [E_col] + [label_col]]

def load_simulated_data(hr, n_obs=1000, num_features=10, num_var=2,
                        average_death=100, end_time=15, method='gaussian',
                        gaussian_config={}, seed=0):
    '''
    Load simulated data generated by exponential distribution.
    :param hr:float
           'lambda_max' hazard ratio.
    :param n_obs:int
           Number of observations.
    :param num_features:int
           Number of features. Default value is 10.
    :param num_var:int
           Number of variables that are really used to generate simulated data.
    :param average_death:int or float.
           Average death time that is the mean of the exponential distribution(\frac{1}{\lambda}).
    :param end_time:int or float.
           Time point that represents an 'end of study'. Any death
           time greater than end_time will be censored.
    :param method:string
           The type of simulated data.'linear' or 'gaussian'.
    :param gaussian_config:dict
           Additional parameters for gaussian simulation.
    :param seed:int
           Random state.
    :return:pandas.DataFrame
           A simulated survival dataset.
    '''

    generator = SimulatedData(hr=hr, average_death=average_death, end_time=end_time,
                              num_features=num_features, num_var=num_var)
    raw_data = generator.generate_data(n_obs, method=method,
                                       gaussian_config=gaussian_config, seed=seed)
    df = pd.DataFrame(raw_data['x'], columns=['x'+str(i) for i in range(1, num_features+1)])
    df['T'], df['E'] = raw_data['T'], raw_data['E']
    return df


def load_data(data_path, T_col='T', E_col='E', exclude_col=[],
              split_ratio=1.0, normalize=False, seed=0):
    '''
    Load csv file and return standard survival data.
    :param data_path:string
           File path. Only supports csv file.
    :param T_col:string
           Column name in raw data representing time.
    :param E_col:string
           Column name in raw data representing events or status.
    :param exclude_col:list
           Columns to be excluded.
    :param split_ratio:float.
           If split_ratio==1.0, the full data will be returned. Otherwise,
           the splitted data will be returned.
    :param normalize:boolean.
           If true, the data will be normalized by column using Z-score transformation.
    :param seed:int
           Random state.
    :return:pandas.DataFrame.
           Or tuple of two DataFrames if split_ratio < 1.0.
    '''
    data_all = pd.read_csv(data_path)

    #list columns out
    Y_cols = [T_col, E_col]
    not_in_x_cols = Y_cols + exclude_col
    X_cols = [col for col in data_all.columns if col not in not_in_x_cols]

    X = data_all[X_cols]
    y = data_all[Y_cols]

    #Normalize data
    if normalize:
        X = X.apply(lambda x: (x - np.mean(x)) / (np.std(x)), axis=0)

    #split the data
    if split_ratio == 1.0:
        X_train, y_train = X, y
    else:
        ss = ShuffleSplit(n_splits=1, test_size=1-split_ratio, random_state=seed)
        for train_idx, test_idx in ss.split(X, y):
            X_train, X_test = X.loc[train_idx,:], X.loc[test_idx,:]
            y_train, y_test = y.loc[train_idx,:], y.loc[test_idx,:]

    if split_ratio == 1.0:
        return pd.concat([X_train, y_train], axis=1)
    else:
        return pd.concat([X_train, y_train], axis=1), pd.concat([X_test, y_test], axis=1)